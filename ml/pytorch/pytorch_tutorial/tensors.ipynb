{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c7b856-d012-4b4e-9ec0-4d537dbacbe1",
   "metadata": {},
   "source": [
    "# PyTorch Tensors\n",
    "- Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
    "- Tensors are used to **encode the inputs and outputs of a model** as well as **model parameters**.\n",
    "- Tensors are similar to NumPy's `ndarray`s, but unlike ndarrays, tensors can be run on **GPUs** and other hardware accelerators.\n",
    "- In fact, tensors and numpy arrays can **share the same memory** and eliminate the need for copying data.\n",
    "- Tensors are **optimized for automatic differentiation** (`autograd`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3d404a-be7d-493d-9da3-19114709b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a834d90-26c4-417d-9917-6f9c0a0735a3",
   "metadata": {},
   "source": [
    "## Initializing a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a4b05-496d-43ee-94b7-996aecdb6451",
   "metadata": {},
   "source": [
    "### Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797a0e69-ee15-4115-a7d3-1fbe7556f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced0c45c-b8df-4b75-98ad-68af91e567a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e74be6-ab84-4f3c-9824-fa249387748d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        Tensor\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "tensor([[1, 2],\n",
       "        [3, 4]])\n",
       "\u001b[0;31mLength:\u001b[0m      2\n",
       "\u001b[0;31mFile:\u001b[0m        /opt/conda/lib/python3.8/site-packages/torch/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   <no docstring>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ef21b1-6992-4d8c-8c3f-4b36f998f7ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
       "\n",
       "Constructs a tensor with no autograd history (also known as a \"leaf tensor\", see :doc:`/notes/autograd`) by copying :attr:`data`.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "    When working with tensors prefer using :func:`torch.Tensor.clone`,\n",
       "    :func:`torch.Tensor.detach`, and :func:`torch.Tensor.requires_grad_` for\n",
       "    readability. Letting `t` be a tensor, ``torch.tensor(t)`` is equivalent to\n",
       "    ``t.clone().detach()``, and ``torch.tensor(t, requires_grad=True)``\n",
       "    is equivalent to ``t.clone().detach().requires_grad_(True)``.\n",
       "\n",
       ".. seealso::\n",
       "\n",
       "    :func:`torch.as_tensor` preserves autograd history and avoids copies where possible.\n",
       "    :func:`torch.from_numpy` creates a tensor that shares storage with a NumPy array.\n",
       "\n",
       "Args:\n",
       "    data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
       "        NumPy ``ndarray``, scalar, and other types.\n",
       "\n",
       "Keyword args:\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "        Default: if ``None``, infers data type from :attr:`data`.\n",
       "    device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor\n",
       "        then the device of data is used. If None and data is not a tensor then\n",
       "        the result tensor is constructed on the CPU.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "    pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
       "        the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
       "\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
       "    tensor([[ 0.1000,  1.2000],\n",
       "            [ 2.2000,  3.1000],\n",
       "            [ 4.9000,  5.2000]])\n",
       "\n",
       "    >>> torch.tensor([0, 1])  # Type inference on data\n",
       "    tensor([ 0,  1])\n",
       "\n",
       "    >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
       "    ...              dtype=torch.float64,\n",
       "    ...              device=torch.device('cuda:0'))  # creates a double tensor on a CUDA device\n",
       "    tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
       "\n",
       "    >>> torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor\n",
       "    tensor(3.1416)\n",
       "\n",
       "    >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
       "    tensor([])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1cd173-c7ce-4ff6-b38a-06be5a530d9e",
   "metadata": {},
   "source": [
    "### From Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad62d70-5e46-4fdd-b6cf-deba5d248053",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f84401-576d-4673-82a2-ba438bcf473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e94dfd7-a343-4431-a775-9e188ad71582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4a714-95a2-49b7-8553-11a1a0c92b03",
   "metadata": {},
   "source": [
    "### From another tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff5f3c2-5b0c-491a-9ac1-9d89c83dd1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.0251, 0.7155],\n",
      "        [0.2948, 0.5701]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17652a3-3569-4aca-b3ff-7b13478bc907",
   "metadata": {},
   "source": [
    "### With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5d4308-01e5-4028-a1b1-8ab4cb8f9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5083, 0.3371, 0.8856],\n",
      "        [0.2167, 0.2616, 0.2405]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112488e-a6f1-46f0-87f0-6ef9167334f6",
   "metadata": {},
   "source": [
    "## Attributes of Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f499bb8b-122f-45de-b89a-7e97b1e16a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6428a6e-d819-4803-90a9-2ce9ea49ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7373, 0.5433, 0.4738, 0.3904],\n",
       "        [0.1637, 0.7357, 0.5085, 0.7052],\n",
       "        [0.1745, 0.1713, 0.7077, 0.2926]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72616c62-3193-4575-908b-8015e4781a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71/1445035615.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor2 = torch.tensor(tensor, device='cuda:2')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7373, 0.5433, 0.4738, 0.3904],\n",
       "        [0.1637, 0.7357, 0.5085, 0.7052],\n",
       "        [0.1745, 0.1713, 0.7077, 0.2926]], device='cuda:2')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.tensor(tensor, device='cuda:2')\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9996afb9-f3b4-4a2f-864f-81820c297a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb85fbe-de96-4d2f-ae17-62f5c2852b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b970d7-2e45-401f-abfa-f21e10234fcb",
   "metadata": {},
   "source": [
    "## Operations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa2034-7085-4501-a1f4-8eacac90d2c7",
   "metadata": {},
   "source": [
    "There are over 100 tensor operations:\n",
    "- creation\n",
    "  - `tensor, sparse_coo_tensor, asarry, as_tensor, as_strided, from_numpy, from_dlpack, frombuffer, zeros, zeros_like, ones, ones_like, arange, range, linspace, logspace, eye, empty, empty_like, empty_strided, full, full_like, quantize_per_tensor, quantize_per_channel, dequantize, complex, polar, heaviside`\n",
    "- indexing, slicing, joining, mutating\n",
    "  - `adjoint, argwhere, cat, concat, concatenate, conj, chunk, dsplit, column_stack, dstack, gather, hsplit, hstack, index_add, index_copy, index_reduce, index_select, masked_select, movedim, moveaxis, narrow, nonzero, permute, reshape, row_stack, select, scatter, diagonal_scatter, slice_scatter, scatter_add, scatter_reduce, split, squeeze, stack, swapaxes, swapdims, t, take, take_along_dim, tensor_split, tile, traspose, unbind, unsqueeze, vsplit, vstack, where`\n",
    "- `Generator`\n",
    "- random sampling\n",
    "  - `seed, manual_seed, initial_seed, get_rng_state, set_rng_state, bernoulli, multinomial, normal, poisson, rand, rand_like, randint, randint_like, randn, randn_like, randperm`\n",
    "- serialization\n",
    "  - `save, load`\n",
    "- parallelism\n",
    "  - `get_num_threads, set_num_threads, get_num_interop_threads, set_num_interop_threads`\n",
    "- gradient computation\n",
    "  - `no_grad, enable_grad, set_grad_enabled, is_grad_enabled, inference_mode, is_inference_mode_enabled`\n",
    "- math pointwise\n",
    "  - `abs, absolute, acos, arccos, acosh, arccosh, add, addcdiv, addcmul, angle, asin, arcsin, asinh, arcsinh, atan, arctan, atanh, arctanh, atan2, arctan2, bitwise_not, bitwise_and, bitwise_or, bitwise_xor, bitwise_left_shift, bitwise_right_shift, ceil, clamp, clip, conj_physical, copysign, cos, cosh, deg2rad, div, divide, digamma, erf, erfc, erfinv, exp, exp2, expm1, fake_quantize_per_channel_affine, fake_quantize_per_tensor_affine, fix, float_power, floor, floor_divide, fmod, frac, frexp, gradient, imag, ldexp, lerp, lgamma, log, log10, log1p, log2, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logit, hypot, i0, igamma, igammac, mul, multiply, mvlgamma, nan_to_num, neg, negative, nextafer, polygamma, positive, pow, quantized_batch_norm, quantized_max_pool1d, quantized_max_pool2d, rad2deg, real, reciprocal, remainder, round, rsqrt, sigmoid, sign, sgn, signbit, sin, sinc, sinh, sqrt, square, sub, subtract, tan, tanh, true_divide, trunc, xlogy`\n",
    "- reduction\n",
    "  - `argmax, argmin, amax, amin, aminmax, all, any, max, min, dist, logsumexp, mean, nanmean, median, nanmedian, mode, norm, nansum, prod, quantile, nanquantile, std, std_mean, sum, unique, unique_consecutive, var, var_mean, count_nonzero`\n",
    "- comparison\n",
    "  - `allclose, argsort, eq, qual, ge, greater_equal, gt, greater, isclose, isfinite, isin, isinf, isposinf, isneginf, isnan, isreal, kthvalue, le, less_equal, lt, less, maximum, minimum, fmax, fmin, ne, not_equal, sort, topk, msort`\n",
    "- spectral\n",
    "  - `stft, istft, bartlett_window, blackman_window, hamming_window, hann_window, kaiser_window`\n",
    "- other ops\n",
    "  - `atleast_1d, atleast_2d, atleast_3d, bincount, block_diag, broadcast_tensors, broadcast_to, broacast_shapes, bucketize, cartesian_prod, cdist, clone, combinations, corrcoef, cov, cross, cummax, cummin, cumprod, cumsum, diag, diag_embed, diagflat, diagonal, diff, einsum, flatten, flip, fliplr, flipup, kron, rot90, gcd, histc, histogram, histogramdd, meshgrid, lcm, logcumsumexp, ravel, renorm, repeat_interleave, roll, searchsorted, tensordot, trace, tril, tril_indices, triu, triu_indices, unflatten, vander, view_as_real, view_as_complex, resolve_conj, resolve_neg`\n",
    "- BLAS, LAPACK\n",
    "  - `addbmm, addmm, addmv, addr, baddbmm, bmm, chain_matmul, cholesky, cholesky_inverse, cholesky_solve, dot, geqrf, ger, inner, inverse, det, logdet, slogdet, lu, lu_solve, lu_unpack, matmul, matrix_power, matrix_exp, mm, mv, orgqr, ormqr, outer, pinverse, qr, svd, svd_lowrank, pca_lowrank, symeig, logpcg, trapz, trapezoid, cumulative_trapezoid, triangular_solve, vdot`\n",
    "- utilities\n",
    "  - `compiled_with_cxx11_abi, result_type, can_cast, promote_types, use_deterministic_algorithms, are_deterministic_algorithms_enabled, is_deterministic_algorithms_warn_only_enabled, set_deterministic_debug_mode, get_deterministic_debug_mode, set_float32_matmul_precision, get_float32_matmul_precision, set_warn_always, is_warn_always_enabled, _assert`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a767bd-820e-4846-91b1-7146a7bcef6d",
   "metadata": {},
   "source": [
    "Each operation can run on GPU. By default, tensors are created on the CPU. Need to explicitly move tensors to GPU using `.to` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315c26e4-4fb9-4191-8348-f3ff808e8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad91375-1650-43c2-a967-05384167dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "Last row: tensor([1., 0., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)\n",
    "print(f'Last row: {tensor[-1]}')\n",
    "print(f'Last column: {tensor[..., -1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "369c67db-986f-4716-ad18-6d9d4d79036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fdc1ae9-4feb-4a23-8e97-978238c3f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e905389a-7d7b-4521-89bf-cf6ea30a8770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c7c140c-2436-42aa-a625-105cc6ce0dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8295927d-8774-404f-8442-871cd8ad056e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1eaeeec-c809-4ba1-bfa5-a76f90aa1e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9577dc1e-596a-4076-bd0c-07f4f91f55b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2617f281-c18f-45f8-bc2d-04c4b85a7ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5108, 0.7833, 0.0190, 0.5554],\n",
       "        [0.8312, 0.7484, 0.9300, 0.7997],\n",
       "        [0.2769, 0.7811, 0.6711, 0.5448],\n",
       "        [0.5352, 0.4821, 0.6399, 0.6909]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed0404-f663-41f5-bc42-f03e037f7540",
   "metadata": {},
   "source": [
    "**Single-element tensors** can be converted to Python value using `.item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1986bd93-d6f8-4405-b6cc-f127f0d05387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg.item(), type(agg.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b3372b0-2ec3-42d7-aaa7-67a6751535e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7abe89-3247-4d60-94f6-8fab83441851",
   "metadata": {},
   "source": [
    "**In-place operations** replace operands with results, and denoted with postfix `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae2a6a00-b5e7-4d62-8b60-d49ee4754268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], device='cuda:0')\n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'{tensor}\\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adff74-8c6f-41f6-ab27-a1364ec4c143",
   "metadata": {},
   "source": [
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332103d-e4c7-4e18-8f95-c44227bf0348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
