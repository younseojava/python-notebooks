{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3dc5c8-aeed-457e-ad2d-f44d76a44297",
   "metadata": {},
   "source": [
    "# PyTorch Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2bba3-9db1-416f-943c-521e6f5ce94c",
   "metadata": {},
   "source": [
    "## Setup for run\n",
    "This Notebook is a test run of PyTorch tutorial targeted for running on AMD GPU.<br>\n",
    "Assuming PyTorch for AMD ROCm is available, for example, inside a appropriately configured Docker container.\n",
    "For example, a Docker image with a tag `rocm/pytorch:rocm5.4_ubuntu20.04_py3.8_pytorch_1.12.1` is used.\n",
    "And the container is created with this command:\n",
    "```\n",
    "docker run -it --device=/dev/kfd --device=/dev/dri --security-opt seccomp=unconfined \\\n",
    "  --group-add video -p 11088:8988 -v $HOME:/myhome --name my-pt-test \\\n",
    "  rocm/pytorch:rocm5.4_ubuntu20.04_py3.8_pytorch_1.12.1 /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b32288-d289-4da5-9ca3-928539f2d224",
   "metadata": {},
   "source": [
    "## Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2dcaa8-aa9d-4fa5-b411-ceabd05e5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9b45f-8d2d-4e4f-a6eb-ef67ba6321e7",
   "metadata": {},
   "source": [
    "Download training and test data from open datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca47615a-56c8-4ab7-b107-215ff1da4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf45d59-9c12-4e7a-81c1-242ea05a5dbd",
   "metadata": {},
   "source": [
    "Create DataLoader by wrapping Dataset, which facilitate handling like batching, sampling, shuffling and multiprocess data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e789866-9112-4d69-ac1b-696f83b12ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W]: {X.shape}')\n",
    "    print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484fa5b2-80a3-4825-bf69-e52861b1d156",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a0abf-edaa-4de1-99b1-3bad5444d19e",
   "metadata": {},
   "source": [
    "Create class inheriting `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8395d7de-5829-45e6-984c-7d564cd99442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17f94ab8-b6af-4be6-9322-ed815ee08f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31bb967b-bde2-4e06-b4dc-d20d54fd67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb83f1-3836-454b-94ec-92f9e9f9a9ea",
   "metadata": {},
   "source": [
    "## Optimizing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f8dcdc-a59a-47b1-8f16-1af79993f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82210647-b723-4a61-9aef-2fc398fe2472",
   "metadata": {},
   "source": [
    "Single training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f417ce0e-b161-4c29-9b3e-ee65acbfd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()  # set train mode\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # back-prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9ae98f8-97fd-442f-9666-dc622e2481eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval()   # set eval(test) mode\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():   # no gradient calculation during test\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b20ff6a9-ad28-4422-ad70-800a47d9075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308357 [    0/60000]\n",
      "loss: 2.298764 [ 6400/60000]\n",
      "loss: 2.281631 [12800/60000]\n",
      "loss: 2.271461 [19200/60000]\n",
      "loss: 2.253024 [25600/60000]\n",
      "loss: 2.217248 [32000/60000]\n",
      "loss: 2.227242 [38400/60000]\n",
      "loss: 2.191671 [44800/60000]\n",
      "loss: 2.188478 [51200/60000]\n",
      "loss: 2.146126 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 2.155049 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.167293 [    0/60000]\n",
      "loss: 2.160949 [ 6400/60000]\n",
      "loss: 2.101174 [12800/60000]\n",
      "loss: 2.113639 [19200/60000]\n",
      "loss: 2.070256 [25600/60000]\n",
      "loss: 1.998778 [32000/60000]\n",
      "loss: 2.022470 [38400/60000]\n",
      "loss: 1.946807 [44800/60000]\n",
      "loss: 1.949832 [51200/60000]\n",
      "loss: 1.867178 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.878420 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.914675 [    0/60000]\n",
      "loss: 1.885818 [ 6400/60000]\n",
      "loss: 1.765454 [12800/60000]\n",
      "loss: 1.803469 [19200/60000]\n",
      "loss: 1.704124 [25600/60000]\n",
      "loss: 1.645429 [32000/60000]\n",
      "loss: 1.659986 [38400/60000]\n",
      "loss: 1.569875 [44800/60000]\n",
      "loss: 1.592818 [51200/60000]\n",
      "loss: 1.482255 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.507073 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.577721 [    0/60000]\n",
      "loss: 1.543446 [ 6400/60000]\n",
      "loss: 1.394144 [12800/60000]\n",
      "loss: 1.462999 [19200/60000]\n",
      "loss: 1.353734 [25600/60000]\n",
      "loss: 1.343348 [32000/60000]\n",
      "loss: 1.353822 [38400/60000]\n",
      "loss: 1.285681 [44800/60000]\n",
      "loss: 1.314212 [51200/60000]\n",
      "loss: 1.218942 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.244739 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.321660 [    0/60000]\n",
      "loss: 1.306551 [ 6400/60000]\n",
      "loss: 1.143290 [12800/60000]\n",
      "loss: 1.245261 [19200/60000]\n",
      "loss: 1.125036 [25600/60000]\n",
      "loss: 1.147250 [32000/60000]\n",
      "loss: 1.165799 [38400/60000]\n",
      "loss: 1.109611 [44800/60000]\n",
      "loss: 1.138686 [51200/60000]\n",
      "loss: 1.062795 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.082052 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.151002 [    0/60000]\n",
      "loss: 1.156841 [ 6400/60000]\n",
      "loss: 0.978744 [12800/60000]\n",
      "loss: 1.108928 [19200/60000]\n",
      "loss: 0.983389 [25600/60000]\n",
      "loss: 1.015934 [32000/60000]\n",
      "loss: 1.047567 [38400/60000]\n",
      "loss: 0.997471 [44800/60000]\n",
      "loss: 1.022856 [51200/60000]\n",
      "loss: 0.963639 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.976747 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.032261 [    0/60000]\n",
      "loss: 1.059337 [ 6400/60000]\n",
      "loss: 0.866581 [12800/60000]\n",
      "loss: 1.018486 [19200/60000]\n",
      "loss: 0.893764 [25600/60000]\n",
      "loss: 0.923989 [32000/60000]\n",
      "loss: 0.969054 [38400/60000]\n",
      "loss: 0.924655 [44800/60000]\n",
      "loss: 0.942526 [51200/60000]\n",
      "loss: 0.897488 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.905067 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.944929 [    0/60000]\n",
      "loss: 0.992002 [ 6400/60000]\n",
      "loss: 0.786528 [12800/60000]\n",
      "loss: 0.954683 [19200/60000]\n",
      "loss: 0.833685 [25600/60000]\n",
      "loss: 0.856530 [32000/60000]\n",
      "loss: 0.913434 [38400/60000]\n",
      "loss: 0.875918 [44800/60000]\n",
      "loss: 0.884296 [51200/60000]\n",
      "loss: 0.850243 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.853415 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.877738 [    0/60000]\n",
      "loss: 0.941623 [ 6400/60000]\n",
      "loss: 0.726794 [12800/60000]\n",
      "loss: 0.907413 [19200/60000]\n",
      "loss: 0.790736 [25600/60000]\n",
      "loss: 0.805557 [32000/60000]\n",
      "loss: 0.871496 [38400/60000]\n",
      "loss: 0.841452 [44800/60000]\n",
      "loss: 0.840306 [51200/60000]\n",
      "loss: 0.814294 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.814162 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.823842 [    0/60000]\n",
      "loss: 0.901313 [ 6400/60000]\n",
      "loss: 0.680165 [12800/60000]\n",
      "loss: 0.870902 [19200/60000]\n",
      "loss: 0.758048 [25600/60000]\n",
      "loss: 0.766188 [32000/60000]\n",
      "loss: 0.837727 [38400/60000]\n",
      "loss: 0.815806 [44800/60000]\n",
      "loss: 0.805845 [51200/60000]\n",
      "loss: 0.785383 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.782874 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.779179 [    0/60000]\n",
      "loss: 0.867269 [ 6400/60000]\n",
      "loss: 0.642301 [12800/60000]\n",
      "loss: 0.841877 [19200/60000]\n",
      "loss: 0.731999 [25600/60000]\n",
      "loss: 0.734886 [32000/60000]\n",
      "loss: 0.808935 [38400/60000]\n",
      "loss: 0.795513 [44800/60000]\n",
      "loss: 0.777900 [51200/60000]\n",
      "loss: 0.760991 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.756754 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.741042 [    0/60000]\n",
      "loss: 0.837277 [ 6400/60000]\n",
      "loss: 0.610634 [12800/60000]\n",
      "loss: 0.818098 [19200/60000]\n",
      "loss: 0.710410 [25600/60000]\n",
      "loss: 0.709633 [32000/60000]\n",
      "loss: 0.783511 [38400/60000]\n",
      "loss: 0.778479 [44800/60000]\n",
      "loss: 0.754519 [51200/60000]\n",
      "loss: 0.739634 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.734261 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.707804 [    0/60000]\n",
      "loss: 0.810207 [ 6400/60000]\n",
      "loss: 0.583687 [12800/60000]\n",
      "loss: 0.798049 [19200/60000]\n",
      "loss: 0.692209 [25600/60000]\n",
      "loss: 0.688605 [32000/60000]\n",
      "loss: 0.760507 [38400/60000]\n",
      "loss: 0.763537 [44800/60000]\n",
      "loss: 0.734334 [51200/60000]\n",
      "loss: 0.720534 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.714377 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.678590 [    0/60000]\n",
      "loss: 0.785467 [ 6400/60000]\n",
      "loss: 0.560331 [12800/60000]\n",
      "loss: 0.780592 [19200/60000]\n",
      "loss: 0.676534 [25600/60000]\n",
      "loss: 0.670878 [32000/60000]\n",
      "loss: 0.739313 [38400/60000]\n",
      "loss: 0.750132 [44800/60000]\n",
      "loss: 0.716769 [51200/60000]\n",
      "loss: 0.703246 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.696495 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.652827 [    0/60000]\n",
      "loss: 0.762754 [ 6400/60000]\n",
      "loss: 0.539805 [12800/60000]\n",
      "loss: 0.765150 [19200/60000]\n",
      "loss: 0.662936 [25600/60000]\n",
      "loss: 0.655747 [32000/60000]\n",
      "loss: 0.719608 [38400/60000]\n",
      "loss: 0.738010 [44800/60000]\n",
      "loss: 0.701328 [51200/60000]\n",
      "loss: 0.687292 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.680257 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.630052 [    0/60000]\n",
      "loss: 0.741853 [ 6400/60000]\n",
      "loss: 0.521676 [12800/60000]\n",
      "loss: 0.751202 [19200/60000]\n",
      "loss: 0.651218 [25600/60000]\n",
      "loss: 0.642703 [32000/60000]\n",
      "loss: 0.701355 [38400/60000]\n",
      "loss: 0.727124 [44800/60000]\n",
      "loss: 0.687860 [51200/60000]\n",
      "loss: 0.672471 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.665443 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.609721 [    0/60000]\n",
      "loss: 0.722612 [ 6400/60000]\n",
      "loss: 0.505531 [12800/60000]\n",
      "loss: 0.738421 [19200/60000]\n",
      "loss: 0.641105 [25600/60000]\n",
      "loss: 0.631415 [32000/60000]\n",
      "loss: 0.684361 [38400/60000]\n",
      "loss: 0.717389 [44800/60000]\n",
      "loss: 0.676204 [51200/60000]\n",
      "loss: 0.658653 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.651900 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.591470 [    0/60000]\n",
      "loss: 0.704917 [ 6400/60000]\n",
      "loss: 0.491012 [12800/60000]\n",
      "loss: 0.726467 [19200/60000]\n",
      "loss: 0.632305 [25600/60000]\n",
      "loss: 0.621631 [32000/60000]\n",
      "loss: 0.668405 [38400/60000]\n",
      "loss: 0.708852 [44800/60000]\n",
      "loss: 0.666187 [51200/60000]\n",
      "loss: 0.645759 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.639486 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.575110 [    0/60000]\n",
      "loss: 0.688559 [ 6400/60000]\n",
      "loss: 0.477967 [12800/60000]\n",
      "loss: 0.715464 [19200/60000]\n",
      "loss: 0.624593 [25600/60000]\n",
      "loss: 0.613066 [32000/60000]\n",
      "loss: 0.653445 [38400/60000]\n",
      "loss: 0.701320 [44800/60000]\n",
      "loss: 0.657694 [51200/60000]\n",
      "loss: 0.633698 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.628098 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.560186 [    0/60000]\n",
      "loss: 0.673457 [ 6400/60000]\n",
      "loss: 0.466142 [12800/60000]\n",
      "loss: 0.705091 [19200/60000]\n",
      "loss: 0.617748 [25600/60000]\n",
      "loss: 0.605588 [32000/60000]\n",
      "loss: 0.639474 [38400/60000]\n",
      "loss: 0.694763 [44800/60000]\n",
      "loss: 0.650477 [51200/60000]\n",
      "loss: 0.622398 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.617627 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.546515 [    0/60000]\n",
      "loss: 0.659544 [ 6400/60000]\n",
      "loss: 0.455413 [12800/60000]\n",
      "loss: 0.695266 [19200/60000]\n",
      "loss: 0.611428 [25600/60000]\n",
      "loss: 0.598953 [32000/60000]\n",
      "loss: 0.626595 [38400/60000]\n",
      "loss: 0.689255 [44800/60000]\n",
      "loss: 0.644336 [51200/60000]\n",
      "loss: 0.611680 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.607973 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.533891 [    0/60000]\n",
      "loss: 0.646691 [ 6400/60000]\n",
      "loss: 0.445607 [12800/60000]\n",
      "loss: 0.685992 [19200/60000]\n",
      "loss: 0.605531 [25600/60000]\n",
      "loss: 0.592957 [32000/60000]\n",
      "loss: 0.614685 [38400/60000]\n",
      "loss: 0.684655 [44800/60000]\n",
      "loss: 0.639076 [51200/60000]\n",
      "loss: 0.601443 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.599040 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.522117 [    0/60000]\n",
      "loss: 0.634765 [ 6400/60000]\n",
      "loss: 0.436512 [12800/60000]\n",
      "loss: 0.677164 [19200/60000]\n",
      "loss: 0.599999 [25600/60000]\n",
      "loss: 0.587481 [32000/60000]\n",
      "loss: 0.603650 [38400/60000]\n",
      "loss: 0.680907 [44800/60000]\n",
      "loss: 0.634634 [51200/60000]\n",
      "loss: 0.591678 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.590766 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.511025 [    0/60000]\n",
      "loss: 0.623645 [ 6400/60000]\n",
      "loss: 0.428140 [12800/60000]\n",
      "loss: 0.668769 [19200/60000]\n",
      "loss: 0.594719 [25600/60000]\n",
      "loss: 0.582426 [32000/60000]\n",
      "loss: 0.593373 [38400/60000]\n",
      "loss: 0.677934 [44800/60000]\n",
      "loss: 0.630897 [51200/60000]\n",
      "loss: 0.582258 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.583122 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.500715 [    0/60000]\n",
      "loss: 0.613324 [ 6400/60000]\n",
      "loss: 0.420343 [12800/60000]\n",
      "loss: 0.660765 [19200/60000]\n",
      "loss: 0.589590 [25600/60000]\n",
      "loss: 0.577763 [32000/60000]\n",
      "loss: 0.583781 [38400/60000]\n",
      "loss: 0.675671 [44800/60000]\n",
      "loss: 0.627778 [51200/60000]\n",
      "loss: 0.573170 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.576028 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.491046 [    0/60000]\n",
      "loss: 0.603702 [ 6400/60000]\n",
      "loss: 0.413068 [12800/60000]\n",
      "loss: 0.653057 [19200/60000]\n",
      "loss: 0.584520 [25600/60000]\n",
      "loss: 0.573321 [32000/60000]\n",
      "loss: 0.574839 [38400/60000]\n",
      "loss: 0.673957 [44800/60000]\n",
      "loss: 0.625141 [51200/60000]\n",
      "loss: 0.564331 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.569434 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.481904 [    0/60000]\n",
      "loss: 0.594730 [ 6400/60000]\n",
      "loss: 0.406293 [12800/60000]\n",
      "loss: 0.645671 [19200/60000]\n",
      "loss: 0.579460 [25600/60000]\n",
      "loss: 0.569026 [32000/60000]\n",
      "loss: 0.566517 [38400/60000]\n",
      "loss: 0.672748 [44800/60000]\n",
      "loss: 0.622860 [51200/60000]\n",
      "loss: 0.555716 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.563289 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.473195 [    0/60000]\n",
      "loss: 0.586344 [ 6400/60000]\n",
      "loss: 0.400051 [12800/60000]\n",
      "loss: 0.638651 [19200/60000]\n",
      "loss: 0.574436 [25600/60000]\n",
      "loss: 0.564839 [32000/60000]\n",
      "loss: 0.558741 [38400/60000]\n",
      "loss: 0.671904 [44800/60000]\n",
      "loss: 0.620893 [51200/60000]\n",
      "loss: 0.547435 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.557560 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.464948 [    0/60000]\n",
      "loss: 0.578493 [ 6400/60000]\n",
      "loss: 0.394177 [12800/60000]\n",
      "loss: 0.631933 [19200/60000]\n",
      "loss: 0.569407 [25600/60000]\n",
      "loss: 0.560728 [32000/60000]\n",
      "loss: 0.551451 [38400/60000]\n",
      "loss: 0.671439 [44800/60000]\n",
      "loss: 0.619196 [51200/60000]\n",
      "loss: 0.539397 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.552215 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.457107 [    0/60000]\n",
      "loss: 0.571185 [ 6400/60000]\n",
      "loss: 0.388642 [12800/60000]\n",
      "loss: 0.625521 [19200/60000]\n",
      "loss: 0.564302 [25600/60000]\n",
      "loss: 0.556688 [32000/60000]\n",
      "loss: 0.544672 [38400/60000]\n",
      "loss: 0.671238 [44800/60000]\n",
      "loss: 0.617700 [51200/60000]\n",
      "loss: 0.531570 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.547213 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.449645 [    0/60000]\n",
      "loss: 0.564350 [ 6400/60000]\n",
      "loss: 0.383380 [12800/60000]\n",
      "loss: 0.619360 [19200/60000]\n",
      "loss: 0.559142 [25600/60000]\n",
      "loss: 0.552650 [32000/60000]\n",
      "loss: 0.538285 [38400/60000]\n",
      "loss: 0.671314 [44800/60000]\n",
      "loss: 0.616343 [51200/60000]\n",
      "loss: 0.524012 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.542538 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.442480 [    0/60000]\n",
      "loss: 0.558014 [ 6400/60000]\n",
      "loss: 0.378404 [12800/60000]\n",
      "loss: 0.613455 [19200/60000]\n",
      "loss: 0.553974 [25600/60000]\n",
      "loss: 0.548593 [32000/60000]\n",
      "loss: 0.532306 [38400/60000]\n",
      "loss: 0.671526 [44800/60000]\n",
      "loss: 0.615071 [51200/60000]\n",
      "loss: 0.516693 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.538160 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.435645 [    0/60000]\n",
      "loss: 0.552068 [ 6400/60000]\n",
      "loss: 0.373741 [12800/60000]\n",
      "loss: 0.607775 [19200/60000]\n",
      "loss: 0.548858 [25600/60000]\n",
      "loss: 0.544581 [32000/60000]\n",
      "loss: 0.526654 [38400/60000]\n",
      "loss: 0.671891 [44800/60000]\n",
      "loss: 0.613825 [51200/60000]\n",
      "loss: 0.509649 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.534050 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.429108 [    0/60000]\n",
      "loss: 0.546501 [ 6400/60000]\n",
      "loss: 0.369337 [12800/60000]\n",
      "loss: 0.602284 [19200/60000]\n",
      "loss: 0.543889 [25600/60000]\n",
      "loss: 0.540507 [32000/60000]\n",
      "loss: 0.521313 [38400/60000]\n",
      "loss: 0.672256 [44800/60000]\n",
      "loss: 0.612584 [51200/60000]\n",
      "loss: 0.502899 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.530186 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.422834 [    0/60000]\n",
      "loss: 0.541299 [ 6400/60000]\n",
      "loss: 0.365221 [12800/60000]\n",
      "loss: 0.597043 [19200/60000]\n",
      "loss: 0.538964 [25600/60000]\n",
      "loss: 0.536437 [32000/60000]\n",
      "loss: 0.516327 [38400/60000]\n",
      "loss: 0.672502 [44800/60000]\n",
      "loss: 0.611345 [51200/60000]\n",
      "loss: 0.496400 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.526544 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.416815 [    0/60000]\n",
      "loss: 0.536463 [ 6400/60000]\n",
      "loss: 0.361293 [12800/60000]\n",
      "loss: 0.592009 [19200/60000]\n",
      "loss: 0.534183 [25600/60000]\n",
      "loss: 0.532374 [32000/60000]\n",
      "loss: 0.511620 [38400/60000]\n",
      "loss: 0.672663 [44800/60000]\n",
      "loss: 0.610097 [51200/60000]\n",
      "loss: 0.490190 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.523110 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.411068 [    0/60000]\n",
      "loss: 0.531913 [ 6400/60000]\n",
      "loss: 0.357597 [12800/60000]\n",
      "loss: 0.587151 [19200/60000]\n",
      "loss: 0.529485 [25600/60000]\n",
      "loss: 0.528374 [32000/60000]\n",
      "loss: 0.507191 [38400/60000]\n",
      "loss: 0.672743 [44800/60000]\n",
      "loss: 0.608829 [51200/60000]\n",
      "loss: 0.484293 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.519868 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.405511 [    0/60000]\n",
      "loss: 0.527685 [ 6400/60000]\n",
      "loss: 0.354104 [12800/60000]\n",
      "loss: 0.582479 [19200/60000]\n",
      "loss: 0.524836 [25600/60000]\n",
      "loss: 0.524407 [32000/60000]\n",
      "loss: 0.503012 [38400/60000]\n",
      "loss: 0.672722 [44800/60000]\n",
      "loss: 0.607551 [51200/60000]\n",
      "loss: 0.478641 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.516795 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.400138 [    0/60000]\n",
      "loss: 0.523751 [ 6400/60000]\n",
      "loss: 0.350762 [12800/60000]\n",
      "loss: 0.577967 [19200/60000]\n",
      "loss: 0.520243 [25600/60000]\n",
      "loss: 0.520500 [32000/60000]\n",
      "loss: 0.498999 [38400/60000]\n",
      "loss: 0.672578 [44800/60000]\n",
      "loss: 0.606254 [51200/60000]\n",
      "loss: 0.473287 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.513877 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.394950 [    0/60000]\n",
      "loss: 0.520084 [ 6400/60000]\n",
      "loss: 0.347572 [12800/60000]\n",
      "loss: 0.573625 [19200/60000]\n",
      "loss: 0.515702 [25600/60000]\n",
      "loss: 0.516671 [32000/60000]\n",
      "loss: 0.495192 [38400/60000]\n",
      "loss: 0.672345 [44800/60000]\n",
      "loss: 0.604906 [51200/60000]\n",
      "loss: 0.468247 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.511097 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.389969 [    0/60000]\n",
      "loss: 0.516661 [ 6400/60000]\n",
      "loss: 0.344538 [12800/60000]\n",
      "loss: 0.569398 [19200/60000]\n",
      "loss: 0.511321 [25600/60000]\n",
      "loss: 0.512865 [32000/60000]\n",
      "loss: 0.491565 [38400/60000]\n",
      "loss: 0.671973 [44800/60000]\n",
      "loss: 0.603583 [51200/60000]\n",
      "loss: 0.463462 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.508452 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.385199 [    0/60000]\n",
      "loss: 0.513434 [ 6400/60000]\n",
      "loss: 0.341664 [12800/60000]\n",
      "loss: 0.565254 [19200/60000]\n",
      "loss: 0.507071 [25600/60000]\n",
      "loss: 0.509217 [32000/60000]\n",
      "loss: 0.488054 [38400/60000]\n",
      "loss: 0.671436 [44800/60000]\n",
      "loss: 0.602229 [51200/60000]\n",
      "loss: 0.458974 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.505927 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.380561 [    0/60000]\n",
      "loss: 0.510377 [ 6400/60000]\n",
      "loss: 0.338854 [12800/60000]\n",
      "loss: 0.561219 [19200/60000]\n",
      "loss: 0.502911 [25600/60000]\n",
      "loss: 0.505709 [32000/60000]\n",
      "loss: 0.484692 [38400/60000]\n",
      "loss: 0.670715 [44800/60000]\n",
      "loss: 0.600803 [51200/60000]\n",
      "loss: 0.454723 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.503510 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.376091 [    0/60000]\n",
      "loss: 0.507445 [ 6400/60000]\n",
      "loss: 0.336164 [12800/60000]\n",
      "loss: 0.557327 [19200/60000]\n",
      "loss: 0.498828 [25600/60000]\n",
      "loss: 0.502305 [32000/60000]\n",
      "loss: 0.481413 [38400/60000]\n",
      "loss: 0.669797 [44800/60000]\n",
      "loss: 0.599331 [51200/60000]\n",
      "loss: 0.450684 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.501199 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.371712 [    0/60000]\n",
      "loss: 0.504651 [ 6400/60000]\n",
      "loss: 0.333551 [12800/60000]\n",
      "loss: 0.553578 [19200/60000]\n",
      "loss: 0.494847 [25600/60000]\n",
      "loss: 0.498989 [32000/60000]\n",
      "loss: 0.478206 [38400/60000]\n",
      "loss: 0.668732 [44800/60000]\n",
      "loss: 0.597731 [51200/60000]\n",
      "loss: 0.446818 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.498978 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.367514 [    0/60000]\n",
      "loss: 0.502032 [ 6400/60000]\n",
      "loss: 0.330956 [12800/60000]\n",
      "loss: 0.549944 [19200/60000]\n",
      "loss: 0.490946 [25600/60000]\n",
      "loss: 0.495708 [32000/60000]\n",
      "loss: 0.475110 [38400/60000]\n",
      "loss: 0.667573 [44800/60000]\n",
      "loss: 0.596147 [51200/60000]\n",
      "loss: 0.443168 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.496846 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.363374 [    0/60000]\n",
      "loss: 0.499560 [ 6400/60000]\n",
      "loss: 0.328457 [12800/60000]\n",
      "loss: 0.546400 [19200/60000]\n",
      "loss: 0.487133 [25600/60000]\n",
      "loss: 0.492496 [32000/60000]\n",
      "loss: 0.472211 [38400/60000]\n",
      "loss: 0.666281 [44800/60000]\n",
      "loss: 0.594660 [51200/60000]\n",
      "loss: 0.439709 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494794 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.359373 [    0/60000]\n",
      "loss: 0.497210 [ 6400/60000]\n",
      "loss: 0.326043 [12800/60000]\n",
      "loss: 0.543067 [19200/60000]\n",
      "loss: 0.483453 [25600/60000]\n",
      "loss: 0.489384 [32000/60000]\n",
      "loss: 0.469413 [38400/60000]\n",
      "loss: 0.664932 [44800/60000]\n",
      "loss: 0.593087 [51200/60000]\n",
      "loss: 0.436441 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.492820 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.355482 [    0/60000]\n",
      "loss: 0.494945 [ 6400/60000]\n",
      "loss: 0.323699 [12800/60000]\n",
      "loss: 0.539856 [19200/60000]\n",
      "loss: 0.479892 [25600/60000]\n",
      "loss: 0.486377 [32000/60000]\n",
      "loss: 0.466798 [38400/60000]\n",
      "loss: 0.663426 [44800/60000]\n",
      "loss: 0.591509 [51200/60000]\n",
      "loss: 0.433407 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.490915 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.351728 [    0/60000]\n",
      "loss: 0.492769 [ 6400/60000]\n",
      "loss: 0.321454 [12800/60000]\n",
      "loss: 0.536775 [19200/60000]\n",
      "loss: 0.476432 [25600/60000]\n",
      "loss: 0.483492 [32000/60000]\n",
      "loss: 0.464230 [38400/60000]\n",
      "loss: 0.661915 [44800/60000]\n",
      "loss: 0.589961 [51200/60000]\n",
      "loss: 0.430523 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.489081 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129c1c9-9a79-4069-8f16-7f0ca321c560",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfe570db-58c2-4c6e-8310-9acda8e41f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch model state to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Saved PyTorch model state to model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2446d-cbc7-412d-a240-eac0b156dc9e",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5178468d-3bd2-474c-b107-1b8a6bfcf0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc2b53-4236-4d58-8356-ad0b23d19a63",
   "metadata": {},
   "source": [
    "Making predictions with the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0158bf5-c0cc-4b0f-8e4c-e568689560d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"T-shirt/top\", Actual: \"T-shirt/top\"\n"
     ]
    }
   ],
   "source": [
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot',]\n",
    "\n",
    "model.eval()   # set inference mode\n",
    "\n",
    "x, y = test_data[201][0], test_data[201][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e7643-c785-4cf6-9f98-176318905e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
